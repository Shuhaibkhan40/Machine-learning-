9) SVM support vector machine
#classification using SVM
import pandas as pd
import numpy as np
dataset = pd.read_csv('titanic2.csv')
print(dataset.shape)
(891, 12)
In [2]:
dataset.head()
Out[2]:
	PassengerId	Pclass	Name	Sex	Age	SibSp	Parch	Ticket	Fare	Cabin	Embarked	Survived
0	1	3	Braund, Mr. Owen Harris	male	22.0	1	0	A/5 21171	7.2500	NaN	S	0
1	2	1	Cumings, Mrs. John Bradley (Florence Briggs Th...	female	38.0	1	0	PC 17599	71.2833	C85	C	1
2	3	3	Heikkinen, Miss. Laina	female	26.0	0	0	STON/O2. 3101282	7.9250	NaN	S	1
3	4	1	Futrelle, Mrs. Jacques Heath (Lily May Peel)	female	35.0	1	0	113803	53.1000	C123	S	1
4	5	3	Allen, Mr. William Henry	male	35.0	0	0	373450	8.0500	NaN	S	0
In [3]:
from sklearn.impute import SimpleImputer
dataset.isnull().sum()
Out[3]:
PassengerId      0
Pclass           0
Name             0
Sex              0
Age            177
SibSp            0
Parch            0
Ticket           0
Fare             0
Cabin          687
Embarked         2
Survived         0
dtype: int64
In [4]:
dataset = dataset.drop(columns=['Name', 'Cabin', 'Embarked'])
In [5]:
dataset.head()
Out[5]:
	PassengerId	Pclass	Sex	Age	SibSp	Parch	Ticket	Fare	Survived
0	1	3	male	22.0	1	0	A/5 21171	7.2500	0
1	2	1	female	38.0	1	0	PC 17599	71.2833	1
2	3	3	female	26.0	0	0	STON/O2. 3101282	7.9250	1
3	4	1	female	35.0	1	0	113803	53.1000	1
4	5	3	male	35.0	0	0	373450	8.0500	0
In [6]:
dataset.isnull().sum()
Out[6]:
PassengerId      0
Pclass           0
Sex              0
Age            177
SibSp            0
Parch            0
Ticket           0
Fare             0
Survived         0
dtype: int64
In [7]:
imp = SimpleImputer(missing_values=np.nan, strategy='mean')
x = dataset.iloc[:,:-1].values

y = dataset.iloc[:,8].values
x
y
Out[7]:
array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,
       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,
       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,
       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,
       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,
       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,
       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0], dtype=int64)
In [8]:
x[:,3:4]=imp.fit_transform(x[:,3:4])
In [9]:
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
x[:,6] = le.fit_transform(x[:,6])
x[:,2] = le.fit_transform(x[:,2])
x
Out[9]:
array([[1, 3, 1, ..., 0, 523, 7.25],
       [2, 1, 0, ..., 0, 596, 71.2833],
       [3, 3, 0, ..., 0, 669, 7.925],
       ...,
       [889, 3, 0, ..., 2, 675, 23.45],
       [890, 1, 1, ..., 0, 8, 30.0],
       [891, 3, 1, ..., 0, 466, 7.75]], dtype=object)
In [10]:
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
transform = ColumnTransformer([('norm1', OneHotEncoder(),[2])],remainder='passthrough')

x =transform.fit_transform(x)
print(x)
[[0.0 1.0 1 ... 0 523 7.25]
 [1.0 0.0 2 ... 0 596 71.2833]
 [1.0 0.0 3 ... 0 669 7.925]
 ...
 [1.0 0.0 889 ... 2 675 23.45]
 [0.0 1.0 890 ... 0 8 30.0]
 [0.0 1.0 891 ... 0 466 7.75]]
In [11]:
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state=0)
In [12]:
from sklearn import svm
lr = svm.SVC()
lr.fit(x_train,y_train)
y_pred = lr.predict(x_test)
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
result = confusion_matrix(y_test, y_pred)
print("Confusion Matrix : ")
print(result)
Confusion Matrix : 
[[102   8]
 [ 50  19]]

4)k nearest neighbour classification using python
import pandas as pd
import numpy as np
df=pd.read_csv("heart.csv")
df.head()
Out[1]:
	age	sex	cp	trtbps	chol	fbs	restecg	thalachh	exng	oldpeak	slp	caa	thall	output
0	60	1	3	145	233	1	0	150	0	2.3	0	0	1	1
1	35	1	2	130	250	0	1	187	0	3.5	0	0	2	1
2	41	0	1	130	204	0	0	172	0	1.4	2	0	2	1
3	55	1	1	120	236	0	1	178	0	0.8	2	0	2	1
4	56	0	0	120	354	0	1	163	1	0.6	2	0	2	1
In [2]:
df.describe()
Out[2]:
	age	sex	cp	trtbps	chol	fbs	restecg	thalachh	exng	oldpeak	slp	caa	thall	output
count	289.000000	289.000000	289.000000	289.000000	289.000000	289.000000	289.000000	289.000000	289.000000	289.000000	289.000000	289.000000	289.000000	289.000000
mean	54.010381	0.678201	1.020761	131.377163	247.961938	0.145329	0.515571	150.231834	0.318339	1.007612	1.418685	0.712803	2.314879	0.570934
std	9.132316	0.467977	1.027192	17.518432	51.596208	0.353043	0.514309	22.899650	0.466640	1.133491	0.613333	1.022596	0.596128	0.495801
min	29.000000	0.000000	0.000000	94.000000	126.000000	0.000000	0.000000	71.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000
25%	47.000000	0.000000	0.000000	120.000000	212.000000	0.000000	0.000000	136.000000	0.000000	0.000000	1.000000	0.000000	2.000000	0.000000
50%	54.000000	1.000000	1.000000	130.000000	243.000000	0.000000	1.000000	154.000000	0.000000	0.600000	1.000000	0.000000	2.000000	1.000000
75%	60.000000	1.000000	2.000000	140.000000	276.000000	0.000000	1.000000	168.000000	1.000000	1.600000	2.000000	1.000000	3.000000	1.000000
max	77.000000	1.000000	3.000000	200.000000	564.000000	1.000000	2.000000	202.000000	1.000000	6.200000	2.000000	4.000000	3.000000	1.000000
In [3]:
df.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 289 entries, 0 to 288
Data columns (total 14 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   age       289 non-null    int64  
 1   sex       289 non-null    int64  
 2   cp        289 non-null    int64  
 3   trtbps    289 non-null    int64  
 4   chol      289 non-null    int64  
 5   fbs       289 non-null    int64  
 6   restecg   289 non-null    int64  
 7   thalachh  289 non-null    int64  
 8   exng      289 non-null    int64  
 9   oldpeak   289 non-null    float64
 10  slp       289 non-null    int64  
 11  caa       289 non-null    int64  
 12  thall     289 non-null    int64  
 13  output    289 non-null    int64  
dtypes: float64(1), int64(13)
memory usage: 31.7 KB
In [4]:
df.isnull().sum()
Out[4]:
age         0
sex         0
cp          0
trtbps      0
chol        0
fbs         0
restecg     0
thalachh    0
exng        0
oldpeak     0
slp         0
caa         0
thall       0
output      0
dtype: int64
In [5]:
from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
In [6]:
y=df.iloc[:,13]
x=df.iloc[:,:-1]
In [7]:
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)
In [8]:
x_train_scaled=scaler.fit_transform(x_train)
x_test_scaled=scaler.fit_transform(x_test)
In [9]:
from sklearn.neighbors import KNeighborsClassifier
lr=KNeighborsClassifier(n_neighbors=5)
lr.fit(x_train_scaled,y_train)
y_pred=lr.predict(x_test_scaled)
In [10]:
from sklearn.metrics import classification_report,confusion_matrix,accuracy_score
result=confusion_matrix(y_test,y_pred)
print("Confusion Matrix: ")
print(result)
Confusion Matrix: 
[[19  8]
 [ 5 26]]
In [11]:
result1=classification_report(y_test,y_pred)
print("Classification Report :",)
print(result1)
Classification Report :
              precision    recall  f1-score   support

           0       0.79      0.70      0.75        27
           1       0.76      0.84      0.80        31

    accuracy                           0.78        58
   macro avg       0.78      0.77      0.77        58
weighted avg       0.78      0.78      0.77        58

In [12]:
result2=round(accuracy_score(y_test,y_pred)*100,2)
print("Acccuracy: ",result2)
Acccuracy:  77.59
